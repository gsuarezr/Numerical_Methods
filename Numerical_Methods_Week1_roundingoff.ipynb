{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45dca38f-72f5-4c01-9511-2ad4e37c0b87",
   "metadata": {},
   "source": [
    "### Notebook 1 - Your computer is a liar "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28588281-fffc-4ef1-b013-2b8234dc61a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Whenever you want to compare numbers your computer may lie to you, it becomes specially evident with simple operations like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2aa687-11b9-4ce1-b469-cb29eb058b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1 + 0.2 == 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5c44ac-053f-48e6-8d93-c61be6b92704",
   "metadata": {},
   "source": [
    "Does it always lie or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706af476-231a-4af8-b8d8-1df86499d32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.3 + 255.0 == 256.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00fb208c-c2f2-4410-b4df-5c19269cf6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.2 + 2.4 + 3.6 == 7.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa809d55-abcb-4b0f-b735-14f391cd953e",
   "metadata": {},
   "source": [
    "Which way does it lie to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08f0eb23-4feb-43e6-a583-36781b30ab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1 + 0.2 <= 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2ebc83-cbe9-43f5-ae59-54b96822a8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10.4 + 20.8 > 31.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ada9daa-9ec5-4e6a-ac77-d2f3815bf958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(20.8-10.4 ) -10.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b7373b-2083-4ead-9dda-94083341647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.8-0.1>0.7 ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8dd2a09-ec70-47a4-a05b-7998e24fb6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.1-0.8<-7 ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43673eb-e32d-4587-b5aa-13f2cd937cca",
   "metadata": {},
   "source": [
    "So what's going on?  Why is your computer lying to you?\n",
    "\n",
    "Well it's not exactly that it's lying it's just the fact that it gets some little extra digits when translating for you. Now wait a sec? What do you mean by translating? Well your computer speaks binary natively while you speak decimal so when you type the number 0.1 into the Python interpreter, it gets stored in memory as a floating-point number (IEEE-754 standard). \n",
    "\n",
    "Here's a conversion that takes place when this happens. 0.1 is a decimal in base 10, but floating-point numbers are stored in binary. In other words, 0.1 gets converted from base 10 to base 2. When your computer translates the resulting binary number may not accurately represent the original base 10 number. 0.1 is one example. To understand this let us go briefly to the way this conversion works\n",
    "Consider the following number 47.03125 . Do you think it can be represent accurately?\n",
    "\n",
    "Let us find out (for this example we will use single precision [[1](https://en.wikipedia.org/wiki/IEEE_754#Basic_and_interchange_formats)]:\n",
    "\n",
    "1. The first step is to separate the number into the whole number and its decimal part\n",
    "\n",
    "![File_2.png](images/File_2.png)\n",
    "\n",
    "\n",
    "2. Then we represent the whole part in binary\n",
    "\n",
    "$47=1 \\times 2^{5}+0 \\times 2^{4}+1 \\times 2^{3}+1 \\times 2^{2}+1 \\times 2^{1}+1 \\times 2^{0}=101111$\n",
    "\n",
    "<span style='color:red '> **3. Then we represent the decimal part in binary** </span> -> This was perhaps the major point of confusion during the lecture\n",
    "\n",
    "\n",
    "$0.03125=0 \\times 2^{-1}+0 \\times 2^{-2}+0 \\times 2^{-3}+0 \\times 2^{-4}+1 \\times 2^{-5}=0.00001$\n",
    "\n",
    "If you're having trouble understanding why it's done this way, think about how you would do it in the decimal system before looking at the image below\n",
    "\n",
    "![File_001.png](images/File_001.png)\n",
    "\n",
    "3. Write things in base 2 \"scientific notation\"\n",
    "\n",
    "$101111.00001=1.0111100001 *2^{5}$\n",
    "\n",
    "Since the First digit in binary scientific notation we may forget about this bit and only use the ones after the decimal point in our Mantissa \n",
    "\n",
    "4.Add bias to the exponent [[1](https://en.wikipedia.org/wiki/IEEE_754#Basic_and_interchange_formats)] and convert it to binary\n",
    "\n",
    "$E=127+5=132=10000100$\n",
    "\n",
    "5. Determine the sign of the number\n",
    "\n",
    "The sign is plot so our sign bit is set to $0$\n",
    "\n",
    "6. Combine Numbers together according to the standard \n",
    "\n",
    "In this example we will use the single precision (32 bits), however if you work with double precision the format is the same, however how many bits are allocated is different for single precision we have \n",
    "\n",
    "- S = 1 Bit ->Sign\n",
    "- E = 8 bits -> Exponent\n",
    "- b = 127 -> Bias\n",
    "- M = 23 bits -> Mantissa\n",
    "\n",
    "![File_000.png](images/File_000.png)\n",
    "\n",
    "\n",
    "While for double precision we have \n",
    "\n",
    "- S = 1 Bit ->Sign\n",
    "- E = 11 bits -> Exponent\n",
    "- b = 127 -> Bias\n",
    "- M = 52 bits -> Mantissa\n",
    "\n",
    "\n",
    "So  47.03125 is represented as :\n",
    "\n",
    "$\\overbrace{0}^S \\underbrace{10000100}_E  \\underbrace{01111000010000000000000}_M$\n",
    "\n",
    "\n",
    "The previous number could be represented acurately on the computer while this is not always the case, take the number 0.1 for example, it's binary representation is:\n",
    "\n",
    "$$ 0.1=0 \\times 2^{-1}+ 0 \\times 2^{-2}+0 \\times 2^{-3}+ 1 \\times 2^{-4}+1 \\times 2^{-5}+ 0 \\times 2^{-6}+0 \\times 2^{-7}+ 1 \\times 2^{-8} +1 \\times 2^{-9}+ 0 \\times 2^{-10} +0 \\times 2^{-11}+1 \\times 2^{-12}+1 \\times 2^{-13}+ 0 \\times 2^{-14}+ 0 \\times 2^{-15}+1 \\times 2^{-16}+ 1 \\times 2^{-17}+0 \\times 2^{-18}+ 0 \\times 2^{-19}+1 \\times 2^{-20}+ 1 \\times 2^{-21}+0 \\times 2^{-22}+ 0 \\times 2^{-23}+1 \\times 2^{-24}+ 1 \\times 2^{-25}+ 0 \\times 2^{-26}+.... $$\n",
    "\n",
    "We just ran out of bits in the mantissa to express 0.1 so what we do now is to round up the last bit we use to express 0.1 to 1, so we aproximate 0.1 to a slightly higher number, the same thing would happen with double precision \n",
    "\n",
    "![File_3.png](images/File_3.png)\n",
    "\n",
    "\n",
    "\n",
    "0.3, also has the same issue. Computer memory is finite, so the infinitely repeating binary fraction representation of 0.3 gets rounded to a finite fraction. That is to say we truncate the above number and fit it into our format, knowing the mantissa is 53 bits long which do you think is the difference bewtween 0.3 and 0.1+0.2 ?\n",
    "\n",
    "**Task**\n",
    "\n",
    "Represent 30.274 in single precision according to the IEEE-754 standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a5a81f02-58c5-4019-988c-4471bb9092e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.551115123125783e-17"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((0.1+0.2)-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41eaf5ea-70bd-431a-b2ff-301ad45a7a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.551115123125783e-17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mantissa in doble precision is 52 bits long, however when using the scientific notation we loose one bit (0 * 2^{-1}) and another is not\n",
    "#considered in the mantissa, then the bit we round up is the 54th\n",
    "2**(-54)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfa5d2-6bb2-4e4e-bd38-7fe94a7c230a",
   "metadata": {},
   "source": [
    "If you want to take a look at the fraction to wich the number is approximated you may use the function below, accordingly it is an example of how to write proper code, evethough from now we are not going to use python anymore the same should hold, you should annotate what the function does and an example in octave as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0bff0b5-d630-47f8-a023-8b34c9be9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to write a proper function\n",
    "def fraction_rep(x:float)->str:\n",
    "    \"\"\"\n",
    "    This function takes a floar x as input and returns the approximate binary \n",
    "    fraction\n",
    "    Example:\n",
    "    >>> fraction_rep(0.1)\n",
    "        '0.1 ≈ 3602879701896397 / 36028797018963968'\n",
    "    \"\"\"\n",
    "    numerator, denominator = (x).as_integer_ratio()\n",
    "    return f\"{x} ≈ {numerator} / {denominator}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc692a7-42df-41f9-8777-e5ce7d3d4562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3 ≈ 5404319552844595 / 18014398509481984'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraction_rep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96c491aa-33c1-4839-bc44-caa2e4fd65c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8 ≈ 3602879701896397 / 4503599627370496'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraction_rep(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e73948b9-430f-41b8-b148-18aeb797400c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0 ≈ 2 / 1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraction_rep(2.0) # Sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281302e0-ea3f-402a-a64a-1615a85672f5",
   "metadata": {},
   "source": [
    "Equalities or inequealities don't work right, what should I do for comparisons? \n",
    "\n",
    "Basicly we consider how close a number is given a certain $\\epsilon$ value. by default it is $1 \\times 10^{-9}$ in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "887afa23-3b4e-486b-9f9d-cc0593471667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import isclose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2af571d0-7a51-4de0-9a9b-5e8c234f019a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isclose((0.1 + 0.2),0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c9e66b3-15f2-47fd-bd38-8adc748ba139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isclose(0.1 + 0.2, 0.3, rel_tol=1e-20) #decreasing the epsilon makes this the same as equality, you should not just decrease it carelessly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d46530-4493-4c7b-ac04-321ecf5b6d51",
   "metadata": {},
   "source": [
    "What about arrays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e55f2d3b-2b44-44a1-b319-b8d65ddb0cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e80e3094-88c2-468e-80ea-e53c1f7076a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array1=np.array([0.1, 0.2]) + np.array([0.2, 0.4])\n",
    "array2=np.array([0.3, 0.6])\n",
    "array1==array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da52dccd-ab6d-4965-b89b-4f31db8c0a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(array1,array2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa652f-ace2-4ec3-b8ea-39d4f18593e3",
   "metadata": {},
   "source": [
    "Due to this issue Can we trust limits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72fe3cee-e183-48fb-a740-00aa48bd197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=lambda x:  np.sin(x)/(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fb01e1b-bc71-4d5f-b116-849f29f1d09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit(1e-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84158598-75d7-4d65-a800-3631d4ea39a8",
   "metadata": {},
   "source": [
    "if $f(x)=\\frac{1-cos(x)}{x^2}$ will the limit $\\lim_{x->0}f(x)$ work ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4a84489-29ef-4b61-ae91-9fcc1ed366b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit2=lambda x: (1-np.cos(x))/(x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9de8acdd-d757-4acb-b482-ffd20d9205f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit2(1e-12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31cbe3-6384-4668-8276-74c8a9e5f1d7",
   "metadata": {},
   "source": [
    "We see that it's false when the number is extremely small but what about, not so small numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28f0e162-c155-4140-8270-d175c1801ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4996003610813205"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit2(1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a261e-168c-4044-9244-04a74282d2b4",
   "metadata": {},
   "source": [
    "Then the limit is well approximated. When dealing with limits numerically it's important to check them since actually approaching the limit may make the computer make mistakes, while not being so close may give you a nice approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e361025-a532-4e8d-84ed-9d05a1ebf2b8",
   "metadata": {},
   "source": [
    "**Task** Can you tell whether the limit $f(x)=x coth(x)$ will work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d851a04-090d-427b-a581-f9eebbac8589",
   "metadata": {},
   "source": [
    "### Does the order of summation matter?\n",
    "\n",
    "Take for example the following expression \n",
    "\n",
    "$x=\\sum_{n=0}^{M} (0.9)^{n}=1+0.9+(0.9)^{2}+ .... + (0.9)^{M}=(0.9)^{M}+(0.9)^{M-1}+......+1$\n",
    "\n",
    "Do you think that it will matter whether we  start doing the sum from the left that is $1+0.9+(0.9)^{2}+....+(0.9)^{M}$ or from the right meaning $(0.9)^{M}+(0.9)^{M-1}+....+1$? \n",
    "\n",
    "Let us explore this situation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8fa1141-df30-4029-91f7-ab4798a1d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suma(M=200,right= False):\n",
    "    \"\"\"\n",
    "    This function performs the sum of (0.9)^{n} with n from 0 to M\n",
    "    if right is False and M to 0 if right is True\n",
    "    >>> suma(right=True)\n",
    "        8.99999999365043\n",
    "    \"\"\"\n",
    "    rg=range(0,M,1) if not right else range(M,0,-1)\n",
    "    result=np.array([(0.9)**i for i in rg]).sum()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ecdb6ca-39b5-461f-88aa-9fdadb5073c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.99999999365043"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma(right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32f40989-d3cd-4e03-bdca-5c2177898c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.999999992944922"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a944374-51e2-44ed-be3c-810f1c8fffe6",
   "metadata": {},
   "source": [
    "Notice that there is a big difference in them. **Task** Which one is a better implementation? \n",
    "\n",
    "*Tip*:  You may find the answer with the help of this link [1](https://en.wikipedia.org/wiki/Geometric_series)\n",
    "\n",
    "**Exercise** Alternate signs using 0.99999 what happens? What is the percentage error?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
